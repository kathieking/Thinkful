{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning 2: missing values Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment\n",
    "\n",
    "In this assignment, you'll be working with the U.S. Education Dataset from Kaggle. The data gives detailed state level information on several facets of the state of education on an annual basis. To learn more about the data and the column descriptions, click the Kaggle link above.\n",
    "\n",
    "Access this data from the Thinkful database using the following credentials:\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'useducation'\n",
    "\n",
    "To complete this assignment, submit a link to a Jupyter notebook containing your solutions to the following tasks:\n",
    "\n",
    "1. Determine all the variable types and find the fraction of the missing values for each variable.\n",
    "2. Notice that the data has a time dimension (year). For this assignment, forget about time and treat all the observations as if they're from the same year. Choose a strategy to deal with the missing values for each variables. For which variables would filling in the missing values with some value make sense? For which might tossing out the records entirely make sense?\n",
    "3. Now, take into account the time factor. Replicate your second answer but this time fill in the missing values by using a statistic that is calculated within the year of the observation. For example, if you want to fill a missing value for a variable with the mean of that variable, calculate the mean by using only the observations for that specific year.\n",
    "4. This time, fill in the missing values using interpolation (extrapolation).\n",
    "5. Compare your results for the 2nd, 3rd, and 4th questions. Do you find any meaningful differences?\n",
    "\n",
    "Submit your work below, and plan on discussing with your mentor. You can also take a look at this example solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: \n",
    "https://www.kaggle.com/noriuk/us-education-datasets-unification-project/home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\katec\\Thinkful\\data_collections\\states_all_extended.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4f953cfebe69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n\u001b[1;32m----> 8\u001b[1;33m     postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0meducation_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'select * from useeducation'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\__init__.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\strategies.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mdbapi_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mdbapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialect_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdbapi_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mdialect_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dbapi\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\psycopg2.py\u001b[0m in \u001b[0;36mdbapi\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'useeducation'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "education_df = pd.read_sql_query('select * from useeducation',con=engine)\n",
    "\n",
    "# no need for an open connection, \n",
    "# as we're only doing a single query\n",
    "#engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Determine all the variable types and find the fraction of the missing values for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Notice that the data has a time dimension (year). For this assignment, forget about time and treat all the observations as if they're from the same year. Choose a strategy to deal with the missing values for each variables. For which variables would filling in the missing values with some value make sense? For which might tossing out the records entirely make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now, take into account the time factor. Replicate your second answer but this time fill in the missing values by using a statistic that is calculated within the year of the observation. For example, if you want to fill a missing value for a variable with the mean of that variable, calculate the mean by using only the observations for that specific year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. This time, fill in the missing values using interpolation (extrapolation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Compare your results for the 2nd, 3rd, and 4th questions. Do you find any meaningful differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'youtube_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7004364ed80c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myoutube_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'youtube_df' is not defined"
     ]
    }
   ],
   "source": [
    "youtube_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "​\n",
    "\n",
    "youtube_df.info()\n",
    "\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5000 entries, 0 to 4999\n",
    "Data columns (total 6 columns):\n",
    "Rank             5000 non-null object\n",
    "Grade            5000 non-null object\n",
    "Channel name     5000 non-null object\n",
    "Video Uploads    5000 non-null object\n",
    "Subscribers      5000 non-null object\n",
    "Video views      5000 non-null int64\n",
    "dtypes: int64(1), object(5)\n",
    "memory usage: 234.5+ KB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'youtube_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-75e4f9172989>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print first rows of the data frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0myoutube_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'youtube_df' is not defined"
     ]
    }
   ],
   "source": [
    "# print first rows of the data frame\n",
    "youtube_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \tRank \tGrade \tChannel name \tVideo Uploads \tSubscribers \tVideo views\n",
    "0 \t1st \tA++ \tZee TV \t82757 \t18752951 \t20869786591\n",
    "1 \t2nd \tA++ \tT-Series \t12661 \t61196302 \t47548839843\n",
    "2 \t3rd \tA++ \tCocomelon - Nursery Rhymes \t373 \t19238251 \t9793305082\n",
    "3 \t4th \tA++ \tSET India \t27323 \t31180559 \t22675948293\n",
    "4 \t5th \tA++ \tWWE \t36756 \t32852346 \t26273668433"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that both Video Uploads and Subscribers are numeric! So, why did these columns appear as object and not int or float?\n",
    "\n",
    "This happened because both Video Uploads and Subscribers contain observations that can't be handled as numeric. This includes both missing values and observations stored in the database as --.\n",
    "\n",
    "To confirm that this is indeed what's happening, let's select the rows where values of the Video Uploads and Subscribers columns are equal to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df[(youtube_df[\"Video Uploads\"].str.strip() == \"--\") | (youtube_df[\"Subscribers\"].str.strip() == \"--\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \tRank \tGrade \tChannel name \tVideo Uploads \tSubscribers \tVideo views\n",
    "17 \t18th \tA+ \tVlad and Nikita \t53 \t-- \t1428274554\n",
    "108 \t109th \tA \tBIGFUN \t373 \t-- \t941376171\n",
    "115 \t116th \tA \tBee Kids Games - Children TV \t740 \t-- \t414535723\n",
    "142 \t143rd \tA \tChiChi TV Siêu Nhân \t421 \t-- \t2600394871\n",
    "143 \t144th \tA \tMusicTalentNow \t1487 \t-- \t3252752212\n",
    "152 \t153rd \tA \tFamily GamesTV \t282 \t-- \t1287242549\n",
    "156 \t157th \tA \tKH Show \t31 \t-- \t106302038\n",
    "175 \t176th \tA \tLES BOYS TV2 \t116 \t-- \t387595623\n",
    "180 \t181st \tA \tBIBO TOYS \t313 \t-- \t1574657579\n",
    "189 \t190th \tA \tKids Tv Show \t8 \t-- \t86516866\n",
    "192 \t193rd \tA \tHappy Funny Kids Toys Pretend Play \t850 \t-- \t1778372917\n",
    "197 \t198th \tA \tLearn Colors Keiki \t6 \t-- \t89116512\n",
    "209 \t210th \tA \tLy LY ToysReview \t33 \t-- \t90941513\n",
    "213 \t214th \tA \tBeat chất lượng cao \t563 \t-- \t622132999\n",
    "223 \t224th \tA \tPurana Hindustan \t91 \t-- \t501921413\n",
    "230 \t231st \tA \tHappy Lives \t188 \t-- \t515722472\n",
    "234 \t235th \tA \tSalih Reis'in Dünyası \t237 \t-- \t2197191069\n",
    "235 \t236th \tA \tNews ThatMatter \t365 \t-- \t77361248\n",
    "238 \t239th \tA \tPlayGammer100 \t7 \t-- \t261227\n",
    "253 \t254th \tA \tFlipkart \t604 \t-- \t718345351\n",
    "255 \t256th \tA \tLos Juguetes BB \t114 \t-- \t82824448\n",
    "267 \t268th \t\tMidnightXChannel \t-- \t-- \t190256974\n",
    "291 \t292nd \tA \tSham Drama شام دراما \t6494 \t-- \t885923365\n",
    "322 \t323rd \tA \tGhiền Phim Hàn \t854 \t-- \t1072407139\n",
    "326 \t327th \tA \tBollywood Event Talkies \t10 \t-- \t350\n",
    "346 \t347th \tA \tJhankar Station 07 \t205 \t-- \t78360362\n",
    "357 \t358th \tA \tPurani Kahani \t66 \t-- \t205282926\n",
    "382 \t383rd \tA \tEl Blog del Narco \t4449 \t-- \t70680037\n",
    "391 \t392nd \tA \tapple kids \t70 \t-- \t370257049\n",
    "392 \t393rd \tA \tDLS News \t1579 \t-- \t514253195\n",
    "... \t... \t... \t... \t... \t... \t...\n",
    "4645 \t4,646th \tB+ \tBangla Gorom News \t1896 \t-- \t151760154\n",
    "4653 \t4,654th \tB+ \tFingerwager \t22 \t-- \t119546477\n",
    "4657 \t4,658th \tB+ \tknowledge master \t806 \t-- \t248868112\n",
    "4663 \t4,664th \tB+ \tPTV Cricket \t1351 \t-- \t132162672\n",
    "4668 \t4,669th \tB+ \tTTV BTW \t69 \t-- \t11325628\n",
    "4687 \t4,688th \tB+ \tعالم الإبداع - Creative… \t216 \t-- \t145773941\n",
    "4690 \t4,691st \tB+ \tTizcall \t68 \t-- \t108495917\n",
    "4695 \t4,696th \tB+ \tMy Tam \t264 \t-- \t538371669\n",
    "4704 \t4,705th \tB+ \tLouie Rochester \t73 \t-- \t75536179\n",
    "4715 \t4,716th \tB+ \tMickey Baby Tv \t47 \t-- \t39117306\n",
    "4730 \t4,731st \tB+ \tPerfect Life \t263 \t-- \t156462604\n",
    "4748 \t4,749th \tB+ \tSamsung South Africa \t311 \t-- \t96264871\n",
    "4771 \t4,772nd \tB+ \tالعالمية للترفية HD \t231 \t-- \t36001078\n",
    "4786 \t4,787th \tB+ \tJustin Wright S. \t458 \t-- \t289623382\n",
    "4802 \t4,803rd \tB+ \tNews Now \t4234 \t-- \t240258091\n",
    "4822 \t4,823rd \tB+ \tمشاهيرنا \t350 \t-- \t51775617\n",
    "4836 \t4,837th \tB+ \tCARS 4 KIDS \t478 \t-- \t1643267574\n",
    "4844 \t4,845th \tB+ \tKhatulistiwa Record \t132 \t-- \t153432783\n",
    "4886 \t4,887th \tB+ \tXpose News \t40476 \t-- \t204810831\n",
    "4892 \t4,893rd \tB+ \tEverything For U \t184 \t-- \t69313209\n",
    "4893 \t4,894th \tB+ \tVB Musicas \t71 \t-- \t48275804\n",
    "4895 \t4,896th \tB+ \tTotoykids Explorer \t165 \t-- \t363738234\n",
    "4898 \t4,899th \t\tExzoticSlice \t-- \t99785 \t9745292\n",
    "4912 \t4,913th \tB+ \tاخترنا لك \t775 \t-- \t95271752\n",
    "4936 \t4,937th \tB+ \t李婶儿说电影 \t139 \t-- \t53572147\n",
    "4941 \t4,942nd \tB+ \tGMTV \t183 \t-- \t127080542\n",
    "4948 \t4,949th \tB+ \tKeivon ToysReview \t468 \t-- \t481568513\n",
    "4956 \t4,957th \tB+ \tCLICKNEWS \t2661 \t-- \t139940815\n",
    "4961 \t4,962nd \tB+ \tONE Championship \t905 \t-- \t109836654\n",
    "4990 \t4,991st \tB+ \tHo Ngoc Ha's Official Channel \t208 \t-- \t127185704\n",
    "\n",
    "390 rows × 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank             5000\n",
    "Grade               6\n",
    "Channel name     4993\n",
    "Video Uploads    2286\n",
    "Subscribers      4612\n",
    "Video views      5000\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the Grade column has only 6 distinct values, so it's safe to classify this as a categorical variable. But Channel name has nearly 5,000 unique values—how can we be sure it's categorical?\n",
    "\n",
    "Here, we must simply think logically about our data. Since Channel name stores the name of the YouTube channel, we can think of each channel as a unique category. The number possibilities this value can take is limited to the number of YouTube channels, so it's a categorical variable.\n",
    "\n",
    "What about the Rank column? Since this contains the rank of each channel, it can be considered as either an ordinal categorical variable or as an interval continuous variable. The variable type we choose will depend on the task at hand and likely some experimentation on the data to decide which is more helpful. As with many tasks in data science, there is no clear-cut \"right\" answer here, so in this bootcamp you will learn how to develop the best course of action given your objectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this method returns group numbers \n",
    "# given video views\n",
    "def categorize_video_views(views_num):\n",
    "    if views_num >= 1000000000:\n",
    "        return 1\n",
    "    elif views_num >= 100000000:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# we use Pandas' .apply() method by calling the function above.\n",
    "youtube_df['views_group'] = youtube_df['Video views'].apply(categorize_video_views)\n",
    "\n",
    "# let's see how many observations we have in each group\n",
    "print(youtube_df.groupby(\"views_group\")[\"Video views\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "views_group\n",
    "1    1399\n",
    "2    2846\n",
    "3     755\n",
    "Name: Video views, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data cleaning 2: missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SQLAlchemy in c:\\users\\katec\\anaconda3\\lib\\site-packages (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'psycopg2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-03ad33532b32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n\u001b[1;32m----> 8\u001b[1;33m     postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0myoutube_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'select * from youtube'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\__init__.py\u001b[0m in \u001b[0;36mcreate_engine\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"strategy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault_strategy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategies\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\strategies.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, name_or_url, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                     \u001b[0mdbapi_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpop_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[0mdbapi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdialect_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdbapi_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mdialect_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dbapi\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sqlalchemy\\dialects\\postgresql\\psycopg2.py\u001b[0m in \u001b[0;36mdbapi\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdbapi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[1;32mimport\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpsycopg2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'psycopg2'"
     ]
    }
   ],
   "source": [
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'youtube'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "youtube_df = pd.read_sql_query('select * from youtube',con=engine)\n",
    "\n",
    "# no need for an open connection, \n",
    "# as we're only doing a single query\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the code above, you'll notice that we accessed Thinkful's database by using some credentials and information about the server like its ip address and the port of the database. All these informations are passed into the create_engine() method of SQLAlchemy as parameters. After that, we called the read_sql_query() method of Pandas by giving the query string and the connection that we established by calling the create_engine() method of SQLAlchemy as parameters. Pandas' read_sql_query() method returns a dataframe as a result of the sql query we run. Notice that after we're done with the database, we close the connection by:\n",
    "\n",
    "engine.dispose()\n",
    "\n",
    "We should always close the connections after we finish our work with the database as it's a best practice for avoiding wasting our computers' and database server's resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'youtube_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7004364ed80c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myoutube_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'youtube_df' is not defined"
     ]
    }
   ],
   "source": [
    "youtube_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5000 entries, 0 to 4999\n",
    "Data columns (total 6 columns):\n",
    "Rank             5000 non-null object\n",
    "Grade            5000 non-null object\n",
    "Channel name     5000 non-null object\n",
    "Video Uploads    5000 non-null object\n",
    "Subscribers      5000 non-null object\n",
    "Video views      5000 non-null int64\n",
    "dtypes: int64(1), object(5)\n",
    "memory usage: 234.5+ KB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output states we have 6 columns and 5,000 rows. Among the columns, only Video views seems to be integer, and the rest appear to be text. However, as we explained in the previous checkpoint, this is misleading.\n",
    "\n",
    "Further investigation in that checkpoint revealed that Video Uploads and Subscribers are also numeric. We will not repeat that analysis here but rather focus on the missing values in the variables and how to treat them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'youtube_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-26df4703dc6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myoutube_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'youtube_df' is not defined"
     ]
    }
   ],
   "source": [
    "youtube_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \tRank \tGrade \tChannel name \tVideo Uploads \tSubscribers \tVideo views\n",
    "0 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "1 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "2 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "3 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "5 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "6 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "7 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "8 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "9 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "10 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "11 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "12 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "13 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "14 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "15 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "16 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "17 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "18 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "19 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "20 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "21 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "22 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "23 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "24 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "25 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "26 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "27 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "28 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "29 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "... \t... \t... \t... \t... \t... \t...\n",
    "4970 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4971 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4972 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4973 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4974 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4975 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4976 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4977 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4978 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4979 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4980 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4981 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4982 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4983 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4984 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4985 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4986 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4987 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4988 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4989 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4990 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4991 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4992 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4993 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4994 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4995 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4996 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4997 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4998 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4999 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "\n",
    "5000 rows × 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_name in youtube_df.columns:\n",
    "    print(\"Unique values in column {} are: {}\".format(column_name, youtube_df[column_name].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unique values in column Rank are: ['1st' '2nd' '3rd' ... '4,998th' '4,999th' '5,000th']\n",
    "Unique values in column Grade are: ['A++ ' 'A+ ' 'A ' '\\xa0 ' 'A- ' 'B+ ']\n",
    "Unique values in column Channel name are: ['Zee TV' 'T-Series' 'Cocomelon - Nursery Rhymes' ... 'Mastersaint'\n",
    " 'Bruce McIntosh' 'SehatAQUA']\n",
    "Unique values in column Video Uploads are: ['82757' '12661' '373' ... '1735' '706' '3475']\n",
    "Unique values in column Subscribers are: ['18752951' '61196302' '19238251' ... '3265735' '32990' '21172']\n",
    "Unique values in column Video views are: [20869786591 47548839843  9793305082 ...   311758426    14563764\n",
    "    73312511]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all values that cannot be converted to float\n",
    "for column_name in [\"Video Uploads\", \"Subscribers\"]:\n",
    "    print(\"These are the problematic values for the variable: {}\".format(column_name))\n",
    "    for value in youtube_df[\"Video Uploads\"]:\n",
    "        try:\n",
    "            float(value)\n",
    "        except:\n",
    "            print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the problematic values for the variable: Video Uploads\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "These are the problematic values for the variable: Subscribers\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n",
    "--\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace \"--\" values to empty strings\n",
    "\n",
    "youtube_df[\"Video Uploads\"] = youtube_df[\"Video Uploads\"].apply(str.strip).replace(\"--\", np.nan)\n",
    "youtube_df[\"Video Uploads\"] = pd.to_numeric(youtube_df[\"Video Uploads\"], downcast=\"float\")\n",
    "\n",
    "youtube_df[\"Subscribers\"] = youtube_df[\"Subscribers\"].apply(str.strip).replace(\"--\", np.nan)\n",
    "youtube_df[\"Subscribers\"] = pd.to_numeric(youtube_df[\"Subscribers\"], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that Video Uploads and Subscribers columns are of type float now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 5000 entries, 0 to 4999\n",
    "Data columns (total 6 columns):\n",
    "Rank             5000 non-null object\n",
    "Grade            5000 non-null object\n",
    "Channel name     5000 non-null object\n",
    "Video Uploads    4994 non-null float32\n",
    "Subscribers      4613 non-null float32\n",
    "Video views      5000 non-null int64\n",
    "dtypes: float32(2), int64(1), object(3)\n",
    "memory usage: 195.4+ KB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the .isnull() method again to check for missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \tRank \tGrade \tChannel name \tVideo Uploads \tSubscribers \tVideo views\n",
    "0 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "1 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "2 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "3 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "5 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "6 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "7 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "8 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "9 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "10 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "11 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "12 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "13 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "14 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "15 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "16 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "17 \tFalse \tFalse \tFalse \tFalse \tTrue \tFalse\n",
    "18 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "19 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "20 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "21 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "22 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "23 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "24 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "25 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "26 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "27 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "28 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "29 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "... \t... \t... \t... \t... \t... \t...\n",
    "4970 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4971 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4972 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4973 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4974 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4975 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4976 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4977 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4978 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4979 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4980 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4981 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4982 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4983 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4984 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4985 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4986 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4987 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4988 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4989 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4990 \tFalse \tFalse \tFalse \tFalse \tTrue \tFalse\n",
    "4991 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4992 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4993 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4994 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4995 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4996 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4997 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4998 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "4999 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "\n",
    "5000 rows × 6 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some True values (check row 17). So far, so good! To get a sense of the magnitude of missing values, let's calculate the percentages of the missing values in all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df.isnull().sum()*100/youtube_df.isnull().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank             0.00\n",
    "Grade            0.00\n",
    "Channel name     0.00\n",
    "Video Uploads    0.12\n",
    "Subscribers      7.74\n",
    "Video views      0.00\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that everything is in order—we identified and fixed the missing values that lurked in Video Uploads and Subscribers. However, let's be sure we haven't overlooked other missing values. Take, for example, the Grade field. This is a categorical variable, so let's print the frequencies for each value: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df.Grade.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B+      2956\n",
    "A-      1024\n",
    "A        963\n",
    "A+        41\n",
    "A++       10\n",
    "           6\n",
    "Name: Grade, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the last row. It appears that we have empty string values which include trailing spaces. These extra spaces mean that they don't show up when we count the missing values! Just because a record looks missing to you, doesn't mean it is to Pandas!\n",
    "\n",
    "Let's convert these records to np.nan and then check whether our changes took effect:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df.Grade = youtube_df.Grade.apply(str.strip).replace(\"\", np.nan)\n",
    "\n",
    "youtube_df.Grade.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array(['A++', 'A+', 'A', nan, 'A-', 'B+'], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears from the nan included in this list of unique values that we have now properly identified the missing values in the Grade column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df[\"Video Uploads\"].fillna(youtube_df[\"Video Uploads\"].mean(), inplace=True)\n",
    "youtube_df[\"Subscribers\"].fillna(youtube_df[\"Subscribers\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df.isnull().sum()*100/youtube_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank             0.000000\n",
    "Grade            0.120144\n",
    "Channel name     0.000000\n",
    "Video Uploads    0.000000\n",
    "Subscribers      0.000000\n",
    "Video views      0.000000\n",
    "dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in missing values in Category with the the value of the next highest-ranked channel's category\n",
    "\n",
    "grade_list = youtube_df.Grade\n",
    "\n",
    "for i in range(0, len(youtube_df.Grade)):\n",
    "    if pd.isnull(youtube_df.Grade[i]):\n",
    "        youtube_df.Grade[i] = youtube_df.Grade[i-1]\n",
    "        \n",
    "youtube_df[\"Grade\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array(['A++', 'A+', 'A', 'A-', 'B+'], dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
